# --- Якоря для переиспользования ---
x-airflow-build: &airflow-build
  build:
    context: ../..
    dockerfile: ./infra/docker/etl/Dockerfile

x-airflow-common-env: &airflow-common-env
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
  AIRFLOW__CELERY__BROKER_URL: redis://redis:6379/1
  AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}

x-airflow-volumes: &airflow-volumes
  - ../../etl/dags:/opt/airflow/dags
  - ../../etl/src:/opt/airflow/src 
  - airflow_logs:/opt/airflow/logs

services:
  # --- Базы данных ---
  mongo:
    image: mongo:latest
    container_name: scb_mongo
    env_file: ./.env
    ports: ["27017:27017"]
    volumes: [mongo_data:/data/db]
    restart: always
    healthcheck: { test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"], interval: 10s, timeout: 5s, retries: 5 }
    networks: [scb_network]

  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: scb_clickhouse
    env_file: ./.env
    ports: ["8123:8123", "9000:9000"]
    volumes: [clickhouse_data:/var/lib/clickhouse]
    restart: always
    ulimits: { nofile: { soft: 262144, hard: 262144 } }
    healthcheck: { test: ["CMD", "wget", "--spider", "-q", "http://localhost:8123/ping"], interval: 10s, timeout: 5s, retries: 5 }
    networks: [scb_network]

  postgres:
    image: postgres:13
    container_name: scb_airflow_postgres
    env_file: ./.env
    restart: always
    volumes: [airflow_postgres_data:/var/lib/postgresql/data]
    healthcheck: { test: ["CMD-SHELL", "pg_isready -U $${POSTGRES_USER} -d $${POSTGRES_DB}"], interval: 10s, timeout: 5s, retries: 5 }
    networks: [scb_network]

  redis:
    image: redis:latest
    container_name: scb_airflow_redis
    restart: always
    healthcheck: { test: ["CMD", "redis-cli", "ping"], interval: 10s, timeout: 5s, retries: 5 }
    networks: [scb_network]

  # --- Сервисы Airflow (Инициализация) ---
  airflow-init:
    <<: *airflow-build
    container_name: scb_airflow_init
    env_file: ./.env
    environment: *airflow-common-env
    volumes: *airflow-volumes
    entrypoint: /bin/bash
    command: >-
      -c "airflow db migrate && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com"
    depends_on:
      postgres: { condition: service_healthy }
      redis: { condition: service_healthy }
    networks: [scb_network]

  # --- Основные приложения ---
  backend:
    build:
      context: ../..
      dockerfile: ./infra/docker/backend/Dockerfile
    container_name: scb_backend
    ports: ["8000:8000"]
    volumes: ["../../backend:/app"]
    env_file: ./.env
    # Блок environment и entrypoint/command удалены
    depends_on:
      mongo: { condition: service_healthy }
      clickhouse: { condition: service_healthy }
    restart: always
    networks: [scb_network]

  frontend:
    build: { context: ../.., dockerfile: ./infra/docker/frontend/Dockerfile }
    container_name: scb_frontend
    ports: ["5173:5173"]
    volumes: ["../../frontend:/app", "/app/node_modules"]
    env_file: ./.env
    command: npm run dev -- --host
    restart: always
    depends_on: [backend]
    networks: [scb_network]

  # --- Сервисы Airflow (Основные) ---
  airflow-webserver:
    <<: *airflow-build
    container_name: scb_airflow_webserver
    restart: always
    env_file: ./.env
    environment: 
      <<: *airflow-common-env
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "True"
    ports: ["8080:8080"]
    volumes: *airflow-volumes
    command: webserver
    healthcheck: { test: ["CMD-SHELL", "curl --fail http://localhost:8080/health"], interval: 30s, timeout: 30s, retries: 5, start_period: 60s }
    depends_on:
      airflow-init: { condition: service_completed_successfully }
    networks: [scb_network]

  airflow-scheduler:
    <<: *airflow-build
    container_name: scb_airflow_scheduler
    restart: always
    env_file: ./.env
    environment: *airflow-common-env # <-- Используйте якорь, если он определен
    volumes: *airflow-volumes
    command: scheduler
    # ДОБАВЬТЕ ЭТОТ БЛОК
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob --hostname $${HOSTNAME}"]
      interval: 1m30s
      timeout: 30s
      retries: 3
      start_period: 5m
    depends_on:
      airflow-init: { condition: service_completed_successfully }
    networks: [scb_network]

  airflow-worker:
    <<: *airflow-build
    container_name: scb_airflow_worker
    restart: always
    env_file: ./.env
    environment: *airflow-common-env
    volumes: *airflow-volumes
    command: celery worker
    depends_on:
      airflow-scheduler: { condition: service_healthy }
    networks: [scb_network]

volumes:
  mongo_data:
  clickhouse_data:
  airflow_postgres_data:
  airflow_logs:

networks:
  scb_network:
    driver: bridge